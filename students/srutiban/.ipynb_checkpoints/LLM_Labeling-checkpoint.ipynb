{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo\n",
    "import re \n",
    "import os\n",
    "import polars as pl\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "# Make sure to create the file OPENAIKEY.txt before running this\n",
    "# (You can use the OPENAIKEY.txt.template file as a template)\n",
    "with open(\"secrets/OPENAIKEY.txt\", \"r\") as f:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MITweet dataset\n",
    "df = pl.read_csv(\"data/mitweet_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMPLE_PROMPT_TEMPLATE = \"\"\"# TWEET\n",
    "{tweet}\n",
    "\n",
    "# ANALYSIS INSTRUCTIONS\n",
    "\n",
    "Use chain-of-thought reasoning to classify this tweet's partisan lean.\n",
    "\n",
    "**Step 1: Summarize the tweet's argument**\n",
    "What is this tweet claiming, advocating, or criticizing?\n",
    "\n",
    "**Step 2: Summarize context**\n",
    "What relevant background information is necessary to understand this tweet's ideological positioning?\n",
    "\n",
    "**Step 3: Determine direction**\n",
    "Based on the tweet and context, which partisan lean does the tweet align with?\n",
    "\n",
    "# RESPONSE FORMAT\n",
    "\n",
    "<analysis>\n",
    "**Tweet's main argument:** [1-2 sentences]\n",
    "\n",
    "**Context:** [1-2 sentence]\n",
    "\n",
    "**Directional assessment:** [Direction] because [1-2 sentence reason]\n",
    "</analysis>\n",
    "\n",
    "<output>\n",
    "[LEFT/CENTER/RIGHT/MIXED]\n",
    "</output>\n",
    "\n",
    "Or if tweet is not political:\n",
    "<output>\n",
    "NONE\n",
    "</output>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_output(output_text: str) -> str:\n",
    "    text = (output_text or \"\").strip()\n",
    "    # Prefer the explicit <output> block if present\n",
    "    m = re.search(r\"<output>\\s*(.*?)\\s*</output>\", text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    if m:\n",
    "        text = m.group(1).strip()\n",
    "    return text.strip().upper()\n",
    "\n",
    "def _query_llm(row: dict) -> dict:\n",
    "    tweet = row[\"tweet\"]\n",
    "    prompt = SIMPLE_PROMPT_TEMPLATE.format(tweet=tweet)\n",
    "    resp = client.responses.create(model=\"gpt-4.1-mini\", input=prompt)\n",
    "    output_text = getattr(resp, \"output_text\", \"\") or \"\"\n",
    "    return output_text\n",
    "\n",
    "\n",
    "# Process rows with a for-loop\n",
    "results = []\n",
    "for row in tqdm(df.iter_rows(named=True), total=df.height):\n",
    "    output_text = _query_llm(row)\n",
    "    prediction = _parse_output(output_text)\n",
    "    # Combine original row data with classification results\n",
    "    result_row = {**row, **{\"llm_output\": output_text, \"prediction\": prediction}}\n",
    "    results.append(result_row)\n",
    "\n",
    "# Convert results back to a DataFrame\n",
    "simple_predictions = pl.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at results\n",
    "pl.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab = (\n",
    "    pl.DataFrame(results)\n",
    "    .group_by('partisan_lean', 'prediction')\n",
    "    .len()\n",
    "    .pivot(index=\"partisan_lean\", on=\"prediction\", values=\"len\")\n",
    ")\n",
    "\n",
    "# Get prediction columns (everything except the index)\n",
    "prediction_columns = [col for col in crosstab.columns if col != \"partisan_lean\"]\n",
    "\n",
    "crosstab = (\n",
    "    crosstab\n",
    "    .with_columns(\n",
    "        pl.concat_str([pl.lit(\"actually_\"), pl.col(\"partisan_lean\")]).alias(\"partisan_lean\")\n",
    "    )\n",
    "    .rename({\n",
    "        \"partisan_lean\": \"actual_label\",\n",
    "        **{col: f\"predicted_{col}\" for col in prediction_columns}\n",
    "    })\n",
    ")\n",
    "\n",
    "crosstab"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "marimo": {
   "app_config": {
    "width": "medium"
   },
   "marimo_version": "0.19.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
